{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_BFqUmxovuBh"},"source":["# Install"]},{"cell_type":"code","metadata":{"id":"VUSOUfRjxRY9"},"source":["!git clone https://github.com/farzane-maghsoudi/TTL-GAN\n","import os\n","os.chdir('TTL-GAN/')\n","!pip install -r requirements.txt\n","!bash ./download_dataset.sh horse2zebra"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3acPlpUwBDo"},"source":["#dataset"]},{"cell_type":"code","metadata":{"id":"dpm-wIZqtKis"},"source":["!bash ./download_dataset.sh horse2zebra"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPKcL0sUxnMR"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"0tTe3RjhxpUV"},"source":["!python main.py --dataset horse2zebra --light True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Restoring from the previous checkpoint"],"metadata":{"id":"hJotgpWWmtYO"}},{"cell_type":"code","source":["!python main.py --dataset horse2zebra --resume True --light True"],"metadata":{"id":"jR887IjrmvIa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3e319da-cbb3-4c01-89e2-e58de009cfbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of epochs must be larger than or equal to one\n","\n","##### Information #####\n","# light :  True\n","# dataset :  horse2zebra\n","# batch_size :  1\n","# iteration per epoch :  300000\n","# the size of image :  256\n","# the size of image channel :  3\n","# base channel number per layer :  64\n","\n","##### Generator #####\n","# residual blocks :  6\n","\n","##### Discriminator #####\n","# discriminator layers :  7\n","\n","##### Weight #####\n","# adv_weight :  1\n","# cycle_weight :  10\n","# recon_weight :  10\n","# feature_weight :  15\n","-----------------------------------------------\n","[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n","[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n","[Network disA] Total number of parameters:  31.630M\n","[Network disA] Total number of FLOPs:  21.197G\n","-----------------------------------------------\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.pixelshuffle.PixelShuffle'>.\n","[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n","[Network gen2B] Total number of parameters:  6.497M\n","[Network gen2B] Total number of FLOPs:  55.349G\n","-----------------------------------------------\n","ok\n","self.start_iter 2001\n","training start !\n","[ 2001/300000] time: 1.5680 d_loss: 3.35197258, g_loss: 17.39024162\n","[ 2002/300000] time: 3.0398 d_loss: 2.15437889, g_loss: 17.69104004\n","[ 2003/300000] time: 4.5143 d_loss: 2.48917103, g_loss: 20.79468918\n","[ 2004/300000] time: 5.9868 d_loss: 2.26533294, g_loss: 19.30231857\n","[ 2005/300000] time: 7.4622 d_loss: 2.70156145, g_loss: 17.93156624\n","[ 2006/300000] time: 8.9373 d_loss: 3.89670539, g_loss: 17.15126419\n","[ 2007/300000] time: 10.4192 d_loss: 3.33603477, g_loss: 14.46301651\n","[ 2008/300000] time: 11.8944 d_loss: 3.37384415, g_loss: 17.57929802\n","[ 2009/300000] time: 13.3797 d_loss: 2.75046968, g_loss: 14.57207680\n","[ 2010/300000] time: 14.8652 d_loss: 3.10389996, g_loss: 17.45340157\n","[ 2011/300000] time: 16.3507 d_loss: 2.73289347, g_loss: 15.33713150\n","[ 2012/300000] time: 17.8394 d_loss: 3.18528748, g_loss: 19.13758469\n","[ 2013/300000] time: 19.3277 d_loss: 3.08536506, g_loss: 19.55790329\n","[ 2014/300000] time: 20.8304 d_loss: 3.58164191, g_loss: 14.74575043\n","[ 2015/300000] time: 22.3166 d_loss: 3.66755724, g_loss: 16.82347870\n","[ 2016/300000] time: 23.8101 d_loss: 3.47605276, g_loss: 16.36749649\n","[ 2017/300000] time: 25.3058 d_loss: 3.09973431, g_loss: 21.40276146\n","[ 2018/300000] time: 26.8002 d_loss: 2.63032246, g_loss: 16.57153893\n","[ 2019/300000] time: 28.3003 d_loss: 3.42993116, g_loss: 16.60978699\n","[ 2020/300000] time: 29.7943 d_loss: 3.85687208, g_loss: 17.16640091\n","[ 2021/300000] time: 31.2934 d_loss: 3.88776159, g_loss: 17.92312050\n","[ 2022/300000] time: 32.7984 d_loss: 2.51260829, g_loss: 18.34976578\n","[ 2023/300000] time: 34.3209 d_loss: 2.63422799, g_loss: 20.53145599\n","[ 2024/300000] time: 35.8254 d_loss: 3.05121183, g_loss: 18.15336418\n","[ 2025/300000] time: 37.3358 d_loss: 3.46618128, g_loss: 15.76860237\n","[ 2026/300000] time: 38.8486 d_loss: 3.27528715, g_loss: 13.89165497\n","[ 2027/300000] time: 40.3621 d_loss: 2.27241421, g_loss: 17.28886032\n","[ 2028/300000] time: 41.8779 d_loss: 2.57944918, g_loss: 18.19582939\n","[ 2029/300000] time: 43.3920 d_loss: 3.91992927, g_loss: 16.72950554\n","[ 2030/300000] time: 44.9102 d_loss: 2.07653236, g_loss: 23.23309326\n","[ 2031/300000] time: 46.4314 d_loss: 2.86656094, g_loss: 16.74726105\n","[ 2032/300000] time: 47.9500 d_loss: 2.96312571, g_loss: 13.69314861\n","[ 2033/300000] time: 49.4804 d_loss: 2.14756155, g_loss: 20.45201302\n","[ 2034/300000] time: 51.0038 d_loss: 2.80563021, g_loss: 16.71099091\n","[ 2035/300000] time: 52.5336 d_loss: 2.16381979, g_loss: 19.61799240\n","[ 2036/300000] time: 54.0643 d_loss: 2.55452585, g_loss: 16.23010635\n","[ 2037/300000] time: 55.5964 d_loss: 2.40419436, g_loss: 16.80387688\n","[ 2038/300000] time: 57.1314 d_loss: 3.44259691, g_loss: 15.41209507\n","[ 2039/300000] time: 58.6683 d_loss: 2.25271225, g_loss: 16.03021622\n","[ 2040/300000] time: 60.2101 d_loss: 2.18918657, g_loss: 20.93921280\n","[ 2041/300000] time: 61.7539 d_loss: 3.19363546, g_loss: 17.24680519\n","[ 2042/300000] time: 63.2967 d_loss: 2.60656333, g_loss: 19.26932144\n","[ 2043/300000] time: 64.8419 d_loss: 3.72581196, g_loss: 15.86831856\n","[ 2044/300000] time: 66.3893 d_loss: 2.86717558, g_loss: 17.35999870\n","[ 2045/300000] time: 67.9385 d_loss: 3.54187083, g_loss: 17.86207581\n","[ 2046/300000] time: 69.4924 d_loss: 2.62427568, g_loss: 19.00100327\n","[ 2047/300000] time: 71.0439 d_loss: 2.40479779, g_loss: 15.92375374\n","[ 2048/300000] time: 72.6014 d_loss: 2.87132668, g_loss: 18.29099846\n","[ 2049/300000] time: 74.1623 d_loss: 3.26045847, g_loss: 16.23708916\n","[ 2050/300000] time: 75.7234 d_loss: 3.10897470, g_loss: 17.58795929\n","[ 2051/300000] time: 77.2828 d_loss: 2.57264972, g_loss: 20.41251755\n","[ 2052/300000] time: 78.8517 d_loss: 4.10036945, g_loss: 16.52379227\n","[ 2053/300000] time: 80.4209 d_loss: 3.91259575, g_loss: 23.70154572\n","[ 2054/300000] time: 81.9910 d_loss: 2.53052902, g_loss: 15.48640251\n","[ 2055/300000] time: 83.5653 d_loss: 2.97157788, g_loss: 14.93688965\n","[ 2056/300000] time: 85.1420 d_loss: 4.44057751, g_loss: 18.32735252\n","[ 2057/300000] time: 86.7218 d_loss: 2.85089469, g_loss: 18.32343864\n","[ 2058/300000] time: 88.2995 d_loss: 2.87544155, g_loss: 17.64190292\n","[ 2059/300000] time: 89.8791 d_loss: 3.71504021, g_loss: 16.82717514\n","[ 2060/300000] time: 91.4636 d_loss: 3.06640887, g_loss: 15.87552261\n","[ 2061/300000] time: 93.0523 d_loss: 3.49516678, g_loss: 14.68843079\n","[ 2062/300000] time: 94.6379 d_loss: 3.25984240, g_loss: 15.21111393\n","[ 2063/300000] time: 96.2196 d_loss: 3.38083220, g_loss: 15.64906406\n","[ 2064/300000] time: 97.8067 d_loss: 2.46182585, g_loss: 17.87828064\n","[ 2065/300000] time: 99.3910 d_loss: 3.24227309, g_loss: 17.82639694\n","[ 2066/300000] time: 100.9790 d_loss: 3.29413319, g_loss: 15.52561760\n","[ 2067/300000] time: 102.5631 d_loss: 4.00897026, g_loss: 17.50583267\n","[ 2068/300000] time: 104.1456 d_loss: 2.94529533, g_loss: 18.46966171\n","[ 2069/300000] time: 105.7217 d_loss: 2.87821674, g_loss: 18.20947838\n","[ 2070/300000] time: 107.2955 d_loss: 2.61255383, g_loss: 19.61250687\n","[ 2071/300000] time: 108.8680 d_loss: 2.60536003, g_loss: 16.76147461\n","[ 2072/300000] time: 110.4402 d_loss: 2.74499607, g_loss: 17.19056511\n","[ 2073/300000] time: 112.0134 d_loss: 3.31870699, g_loss: 15.60168266\n","[ 2074/300000] time: 113.5789 d_loss: 2.07378340, g_loss: 21.25892067\n","[ 2075/300000] time: 115.1430 d_loss: 3.49188042, g_loss: 15.87033272\n","[ 2076/300000] time: 116.7120 d_loss: 3.84920907, g_loss: 18.50275993\n","[ 2077/300000] time: 118.2761 d_loss: 3.07626629, g_loss: 17.86170769\n","[ 2078/300000] time: 119.8410 d_loss: 3.80075860, g_loss: 16.86485672\n","[ 2079/300000] time: 121.4057 d_loss: 3.29684591, g_loss: 18.85127640\n","[ 2080/300000] time: 122.9691 d_loss: 3.29576015, g_loss: 17.61458015\n","[ 2081/300000] time: 124.5341 d_loss: 3.51249933, g_loss: 17.64862823\n","[ 2082/300000] time: 126.0978 d_loss: 2.54363775, g_loss: 15.88748360\n","[ 2083/300000] time: 127.6617 d_loss: 2.43779850, g_loss: 16.41876602\n"]}]},{"cell_type":"markdown","metadata":{"id":"-sXLWEvaxqVl"},"source":["#Testing"]},{"cell_type":"code","metadata":{"id":"hjeKtGGgxwPT"},"source":["!python main.py --dataset mini --phase test --light True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sgxUHjCmc-jN"},"source":["#Copy checkpoint to GoogleDrive and convert\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"o0kgt7hBdR_j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664460285579,"user_tz":-210,"elapsed":51289,"user":{"displayName":"Farzane Maghsoudi","userId":"02314889163660992937"}},"outputId":"317eb57f-84cd-412b-829a-046e938d78bb"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!mkdir ./results"],"metadata":{"id":"NJh19kB6nIuV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b = \"/content/gdrive/MyDrive/checkpointTTL-GAN/horse2zebra_params_latest.pt\"\n","c = \"/content/TTL-GAN/results/horse2zebra_params_latest.pt\"\n","f1 = \"/content/gdrive/MyDrive/checkpointTTL-GAN/horse2zebra_params_0002000.pt\"\n","f2 = \"/content/TTL-GAN/results/horse2zebra/model/horse2zebra_params_0002000.pt\"\n","cc = \"/content/TTL-GAN/results/horse2zebra_params_0002000.pt\""],"metadata":{"id":"RpzcPQewnN7z","executionInfo":{"status":"ok","timestamp":1664466054145,"user_tz":-210,"elapsed":625,"user":{"displayName":"Farzane Maghsoudi","userId":"02314889163660992937"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4WYiXhHHe-JP"},"source":["Colab to Drive"]},{"cell_type":"code","metadata":{"id":"0PhFuKZxaokL"},"source":["import shutil\n","shutil.copy( c , b )\n","shutil.copy( f2 , f1 )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUlQqL_GfXLf"},"source":["Drive to Colab"]},{"cell_type":"code","metadata":{"id":"b8C1wN-1dPAf","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1664466060043,"user_tz":-210,"elapsed":1287,"user":{"displayName":"Farzane Maghsoudi","userId":"02314889163660992937"}},"outputId":"ab67d5ae-f4c9-491d-bc98-9296a6543d81"},"source":["import shutil\n","shutil.copy( f1 , cc )"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/TTL-GAN/results/horse2zebra_params_0002000.pt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"kPBCXY52DQdb"},"source":["#Test save"]},{"cell_type":"code","metadata":{"id":"gOoPpNiSDcvJ"},"source":["#import shutil\n","#b = \"/content/gdrive/MyDrive/results/501/UGATIT_light_apple2orange_lsgan_4resblock_6dis_1_1_10_10_1000_1_1_1_sn_smoothing\"\n","#c = \"/content/UG/results/UGATIT_light_apple2orange_lsgan_4resblock_6dis_1_1_10_10_1000_1_1_1_sn_smoothing\"\n","!cp \"/content/UG/results/UGATIT_light_apple2orange_lsgan_4resblock_6dis_1_1_10_10_1000_1_1_1_sn_smoothing\" -r \"/content/gdrive/MyDrive/results\""],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_blocks = 8\n","for i in range(2, n_blocks+1):\n","  if i%3 == 0:\n","    x2 = 3\n","    print (i, x2)\n","  if i%3 == 1:\n","    x3 = 4\n","    print (i, x3)\n","  if i%3 == 2:\n","    if i> 4:\n","      x4 = 10\n","      print (i, x4)\n","    else:\n","      x4 = 5\n","      print (i, x4)"],"metadata":{"id":"_0jBVxT9ZZIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","a = torch.randn(1,256, 64, 64)\n","#a = torch.reshape(a, (256, 64, 64))\n","atten  = torch.nn.MultiheadAttention(64, 8)\n","relu = torch.nn.ReLU(True)\n","class MultiSelfAttentionBlock(nn.Module):\n","    def __init__(self, atten, relu, dim =64, featur = 256):\n","      super(MultiSelfAttentionBlock, self).__init__()\n","      self.dim = dim\n","      self.featur = featur\n","      self.atten  = atten\n","      self.relu  = relu\n","\t\t\n","\t\t\n","    def forward(self, x):\n","      print(\"as\")\n","      out = torch.reshape(x, (self.featur, self.dim, self.dim))\n","      out, _ = self.atten(out, out, out)\n","      out = self.relu(torch.reshape(out, (1, self.featur, self.dim, self.dim)))\n","      print(\"a\")\n","\n","      return out\n","\n","#out, _ = atten(a, a, a)\n","#out = torch.reshape(out, (1, 256, 64, 64))\n","for i in range(3):\n","  out = MultiSelfAttentionBlock(a, atten, relu)\n","  #print (out.shape)"],"metadata":{"id":"HikzH9oaeI0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","a = torch.randn(1,256, 64, 64)\n","atten  = torch.nn.MultiheadAttention(64, 8)\n","relu = torch.nn.ReLU(True)\n","for i in range(3):\n","  print(\"as\")\n","  out = torch.reshape(a, (256, 64, 64))\n","  out, _ = atten(out, out, out)\n","  out = torch.reshape(out, (1, 256, 64, 64))\n","  out = relu(out)\n","  print(\"a\")\n","  print (out.shape)"],"metadata":{"id":"rkky1MiGLiVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","x = torch.randn(1,256, 64, 64)\n","atten  = torch.nn.MultiheadAttention(64, 8)\n","relu = torch.nn.ReLU(True)\n","n_blocks = 8\n","out = torch.reshape(x, (256, 64, 64))\n","out, _ = atten(out, out, out)\n","out = relu(torch.reshape(out, (1, 256, 64, 64)))\n","xa1 = out\n","xa11 = out\n","if n_blocks>1:\n","  for i in range(2, 8+1):\n","    if i%3 == 2:\n","      out = torch.reshape(out, (256, 64, 64))\n","      out, _ = atten(out, out, out)\n","      xa2 = out = relu(torch.reshape(out, (1, 256, 64, 64)))\n","      print (i)\n","    elif i%3 == 0:\n","      out = torch.reshape(out + xa1, (256, 64, 64))\n","      out, _ = atten(out, out, out)\n","      xa3 = out = relu(torch.reshape(out, (1, 256, 64, 64)))\n","      print (i)\n","    elif i < 6:\n","      out = torch.reshape(out + xa1 + xa2, (256, 64, 64))\n","      out, _ = atten(out, out, out)\n","      xa1 = out = relu(torch.reshape(out, (1, 256, 64, 64)))\n","      print (i)\n","    else:\n","      out = torch.reshape(out + xa1 + xa2 + xa11, (256, 64, 64))\n","      out, _ = atten(out, out, out)\n","      xa11 = xa1\n","      xa1 = out = relu(torch.reshape(out, (1, 256, 64, 64)))\n","      print (i)"],"metadata":{"id":"xS0FWeH5PWC_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","a = torch.randn(1,128, 56, 56)\n","b = torch.randn(1,128, 28, 28)\n","c = torch.randn(1,128, 14, 14)\n","up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","up2 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n","pad1 = nn.ReflectionPad2d(4)\n","pad2 = nn.ReflectionPad2d(4)\n","pad3 = nn.ReflectionPad2d(4)\n","a = pad1 (a)\n","b = up1(b)\n","b = pad2(b)\n","c = up2(c)\n","c = pad3(c)\n","print (a.shape)\n","print(b.shape)\n","print(c.shape)"],"metadata":{"id":"Uqtv7XcgpkDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["self.save(self.checkpoint_dir, counter)\n","\t\t\t\t    a = (epoch+1)*1000\n","\t\t\t\t    b = \"/content/gdrive/MyDrive/checkpoint/UGATIT_light_apple2orange_lsgan_4resblock_6dis_1_1_10_10_1000_1_1_1_sn_smoothing\"\n","\t\t\t\t    c = \"/content/UG/checkpoint/UGATIT_light_apple2orange_lsgan_4resblock_6dis_1_1_10_10_1000_1_1_1_sn_smoothing\"\n","\t\t\t\t    f1 = \"/UGATIT_light.model-\"+ str(a)+ \".index\"\n","\t\t\t\t    f2 = \"/UGATIT_light.model-\"+ str(a)+ \".meta\"\n","\t\t\t\t    f3 = \"/UGATIT_light.model-\" + str(a)+ \".data-00000-of-00001\"\n","\t\t\t\t    f = \"/checkpoint\"\n","\t\t\t\t    import shutil\n","\t\t\t\t    shutil.copy( c+f1 , b+f1 )\n","\t\t\t\t    shutil.copy( c+f2 , b+f2 )\n","\t\t\t\t    shutil.copy( c+f3 , b+f3 )\n","\t\t\t\t    shutil.copy( c+f , b+f )"],"metadata":{"id":"1C0aM6hMi83r"},"execution_count":null,"outputs":[]}]}
